"""
[Global Pulse Phase 2] â€” Pulse Service
Provides network-wide intelligence stats for the Global Pulse dashboard widget.

EXPLANATION:
This service queries real-time metrics about the shared intelligence network:
- active_users_count: Users with at least 1 tracked hotel
- hotels_monitored: Distinct hotels across the entire network (by serp_api_id)
- cache_hits_24h / total_scans_24h: Measures how effective the 3-hour cache is
- estimated_savings: API credits saved by cache hits (each hit = 1 SerpApi credit saved)
"""

import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any
from supabase import Client

from backend.utils.logger import get_logger

logger = get_logger(__name__)

# EXPLANATION: In-memory cache for network stats
# Network stats don't change rapidly, so we cache for 5 minutes
# to avoid hitting the database on every dashboard load.
_STATS_CACHE: Dict[str, Any] = {"data": None, "timestamp": 0}
_STATS_CACHE_TTL = 300  # 5 minutes


async def get_pulse_network_stats(db: Client) -> Dict[str, Any]:
    """
    Returns live network metrics for the Global Pulse dashboard widget.
    Cached for 5 minutes to reduce DB load while keeping stats reasonably fresh.
    """
    global _STATS_CACHE

    if time.time() - _STATS_CACHE["timestamp"] < _STATS_CACHE_TTL and _STATS_CACHE["data"]:
        return _STATS_CACHE["data"]

    try:
        if not db:
             logger.warning("Pulse: Database connection unavailable")
             return {
                "active_users_count": 0,
                "hotels_monitored": 0,
                "cache_hit_rate_24h": 0,
                "total_scans_24h": 0,
                "cache_hits_24h": 0,
                "estimated_savings_credits": 0,
                "updated_at": datetime.now(timezone.utc).isoformat()
            }
        # EXPLANATION: We run 4 lightweight count queries.
        # These are fast index scans on Supabase/PostgreSQL.

        # 1. Active users: users who have at least 1 hotel
        active_users_count = 0
        try:
            users_res = db.table("hotels") \
                .select("user_id") \
                .execute()
            unique_users = set(h["user_id"] for h in (users_res.data or []))
            active_users_count = len(unique_users)
        except Exception as e:
            logger.warning(f"Pulse: Failed to count active users: {e}")

        # 2. Monitored hotels: distinct serp_api_ids across all users
        hotels_monitored = 0
        try:
            hotels_res = db.table("hotels") \
                .select("serp_api_id") \
                .not_.is_("serp_api_id", "null") \
                .execute()
            unique_hotels = set(h["serp_api_id"] for h in (hotels_res.data or []))
            hotels_monitored = len(unique_hotels)
        except Exception as e:
            logger.warning(f"Pulse: Failed to count monitored hotels: {e}")

        # 3. Cache performance: count scans in last 24h and those tagged as cache hits
        cutoff_24h = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat()
        
        # Total scans in 24h
        total_scans_24h = 0
        try:
            scans_res = db.table("price_logs") \
                .select("id", count="exact") \
                .gte("recorded_at", cutoff_24h) \
                .execute()
            total_scans_24h = scans_res.count or 0
        except Exception as e:
            logger.warning(f"Pulse: Failed to count total scans: {e}")

        # Cache hits: price_logs where source = 'global_pulse_cache'
        # EXPLANATION: We check for a 'source' field. If it doesn't exist yet,
        # we estimate cache hits from Global Pulse alerts (conservative estimate).
        cache_hits_24h = 0
        try:
            pulse_alerts_res = db.table("alerts") \
                .select("id", count="exact") \
                .ilike("message", "%Global Pulse%") \
                .gte("created_at", cutoff_24h) \
                .execute()
            # Each pulse alert represents at least 1 cache-served result
            cache_hits_24h = pulse_alerts_res.count or 0
        except Exception:
            pass

        # 4. Calculate cache hit rate and savings
        cache_hit_rate = round((cache_hits_24h / max(total_scans_24h, 1)) * 100, 1)
        # Each cache hit saves ~$0.01 per SerpApi credit
        estimated_savings = cache_hits_24h  # In API credits

        stats = {
            "active_users_count": active_users_count,
            "hotels_monitored": hotels_monitored,
            "cache_hit_rate_24h": cache_hit_rate,
            "total_scans_24h": total_scans_24h,
            "cache_hits_24h": cache_hits_24h,
            "estimated_savings_credits": estimated_savings,
            "updated_at": datetime.now(timezone.utc).isoformat()
        }

        _STATS_CACHE = {"data": stats, "timestamp": time.time()}
        return stats

    except Exception as e:
        logger.error(f"[PulseService] Failed to fetch network stats: {e}")
        return {
            "active_users_count": 0,
            "hotels_monitored": 0,
            "cache_hit_rate_24h": 0,
            "total_scans_24h": 0,
            "cache_hits_24h": 0,
            "estimated_savings_credits": 0,
            "updated_at": datetime.now(timezone.utc).isoformat()
        }
